{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"# TODO DELETE ME\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"# TODO DELETE ME\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO DELETE ME\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_formatted_code = \"import warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\nimport math\\n\\n# to set random seed\\nimport numpy as np\\n\\n# used to create CRF model\\nfrom sklearn_crfsuite import CRF\\n\\n# used to evaluate model\\nfrom sklearn_crfsuite import metrics\\n\\n# for specifying f1 metrics\\nfrom sklearn.metrics import make_scorer\\n\\n# for cross validation of hyperparameters\\nfrom sklearn.model_selection import RandomizedSearchCV\\n\\n# to visualize the weight of parameters of the fitted model\\nimport eli5\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\nimport math\\n\\n# to set random seed\\nimport numpy as np\\n\\n# used to create CRF model\\nfrom sklearn_crfsuite import CRF\\n\\n# used to evaluate model\\nfrom sklearn_crfsuite import metrics\\n\\n# for specifying f1 metrics\\nfrom sklearn.metrics import make_scorer\\n\\n# for cross validation of hyperparameters\\nfrom sklearn.model_selection import RandomizedSearchCV\\n\\n# to visualize the weight of parameters of the fitted model\\nimport eli5\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# to set random seed\n",
    "import numpy as np\n",
    "\n",
    "# used to create CRF model\n",
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "# used to evaluate model\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "# for specifying f1 metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# for cross validation of hyperparameters\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# to visualize the weight of parameters of the fitted model\n",
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"pd.set_option(\\\"max_row\\\", 600)\";\n",
       "                var nbb_formatted_code = \"pd.set_option(\\\"max_row\\\", 600)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option(\"max_row\", 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"np.random.seed(42)\";\n",
       "                var nbb_formatted_code = \"np.random.seed(42)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"data = pd.read_csv(\\\"tagged_data.csv\\\", index_col=0)\";\n",
       "                var nbb_formatted_code = \"data = pd.read_csv(\\\"tagged_data.csv\\\", index_col=0)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"tagged_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence#</th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Preheat</td>\n",
       "      <td>VB</td>\n",
       "      <td>U-Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>oven</td>\n",
       "      <td>NN</td>\n",
       "      <td>U-Utensil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>to</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>425</td>\n",
       "      <td>CD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>degrees</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>F.</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Press</td>\n",
       "      <td>NN</td>\n",
       "      <td>U-Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>dough</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>into</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence#     word  pos        tag\n",
       "0        0.0  Preheat   VB   U-Action\n",
       "1        0.0     oven   NN  U-Utensil\n",
       "2        0.0       to   IN          O\n",
       "3        0.0      425   CD          O\n",
       "4        0.0  degrees  NNS          O\n",
       "5        0.0       F.   NN          O\n",
       "6        1.0    Press   NN   U-Action\n",
       "7        1.0    dough   NN          O\n",
       "8        1.0     into   IN          O\n",
       "9        1.0      the   DT          O"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"data.head(10)\";\n",
       "                var nbb_formatted_code = \"data.head(10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parse_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1e3ded55a1b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Set the sentence# as index for merging ID:212 to ID:263\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mparse_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sentence#\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mparse_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'parse_data' is not defined"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# Set the sentence# as index for merging ID:212 to ID:263\\nparse_data.set_index(\\\"sentence#\\\", inplace=True)\\nparse_data.tail()\";\n",
       "                var nbb_formatted_code = \"# Set the sentence# as index for merging ID:212 to ID:263\\nparse_data.set_index(\\\"sentence#\\\", inplace=True)\\nparse_data.tail()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the sentence# as index for merging ID:212 to ID:263\n",
    "parse_data.set_index(\"sentence#\", inplace=True)\n",
    "parse_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the words with same sentence#\n",
    "combined_sentence = (\n",
    "    parse_data.groupby([\"sentence#\"])[\"word\"]\n",
    "    .apply(lambda x: \" \".join(x.astype(str)))\n",
    "    .reset_index()\n",
    ")\n",
    "combined_sentence.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to the nested list\n",
    "combined_sentences_list = combined_sentence.reset_index()[\n",
    "    [\"sentence#\", \"word\"]\n",
    "].values.tolist()\n",
    "for item in combined_sentences_list:\n",
    "    print(item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(combined_sentence_list)\n",
    "dp_picked_sent = []\n",
    "not_dp_picked_sent  = []\n",
    "\n",
    "# Get the sentence for SpaCy\n",
    "for sentence in combined_sentences_list:\n",
    "    # Locate the sentence element\n",
    "    ind_sentences = sentence[1]\n",
    "    # Create SpaCy doc\n",
    "    doc = nlp(ind_sentences)\n",
    "\n",
    "    # Get the action words\n",
    "    for token in doc:\n",
    "        # print(token)\n",
    "\n",
    "        # Pick all the Verb in pos_, and anything but advcl in dep_\n",
    "        if token.pos_ == \"VERB\" and token.dep_ != \"advcl\":\n",
    "            # print(int(sentence[0]), \" \".join([token.dep_ for token in doc]))\n",
    "            dp_parser = \" \".join([token.dep_ for token in doc])\n",
    "            dp_picked_sent.append((int(sentence[0]), dep_parser))\n",
    "        ###################################################\n",
    "        # HELP: How to pick up the rest of missed setence ID and setnece itself\n",
    "        # else:\n",
    "        #      not_dp_picked_sent.append(sentence[0])\n",
    "        #####################################################\n",
    "        # if token.dep_ == \"ROOT\" or token.dep_ == \"conj\" or token.dep_ == \"nmod\" or token.dep_ == \"advcl\":\n",
    "        # print(doc, \"---->>>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\n",
    "    \"Total # of sentences:\",\n",
    "    len(combined_sentences_list),\n",
    "    \"\\n# of Dependency Parser PICKED sentences:\",\n",
    "    len(set(dp_picked_sent)),\n",
    "    \"\\nMISSED sentences ID:\", 212, 213, 217, 226, 233, 259\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(\n",
    "    \"Remove from freezer and place waxed paper between each burger as you stack them .\"\n",
    ")\n",
    "displacy.serve(doc1, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# The end\n",
    "##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tag\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data[\"word\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(data[\"word\"].values))\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func = lambda s: [\n",
    "    (w, p, t)\n",
    "    for w, p, t in zip(\n",
    "        s[\"word\"].values.tolist(), s[\"pos\"].values.tolist(), s[\"tag\"].values.tolist()\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = data.groupby(\"sentence#\").apply(agg_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [s for s in grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        # capture the proportion of a given label in the training set\n",
    "        \"bias\": 1.0,\n",
    "        # get the lower case form of the word\n",
    "        \"word.lower()\": word.lower(),\n",
    "        # get last 3 letters for the word\n",
    "        \"word[-3:]\": word[-3:],\n",
    "        # get last 2 letters for the word\n",
    "        \"word[-2:]\": word[-2:],\n",
    "        # check whether the word is uppercase or not\n",
    "        \"word.isupper()\": word.isupper(),\n",
    "        # check whether the word is title case or not\n",
    "        \"word.istitle()\": word.istitle(),\n",
    "        # check whether the word is digit or not, useful to identifying quantities which will be tagged as 'O'\n",
    "        \"word.isdigit()\": word.isdigit(),\n",
    "        # specifying the pos for word\n",
    "        \"postag\": postag,\n",
    "        # get first 2 letters for the POS tag\n",
    "        \"postag[:2]\": postag[:2],\n",
    "        # check if word is symbol or not\n",
    "        \"non_symbol_checker\": word not in [\"(\", \")\", \".\", \",\"],\n",
    "    }\n",
    "\n",
    "    # if word is starting of sentence\n",
    "    if i > 0:\n",
    "\n",
    "        # if word is not the beginning of sentence\n",
    "        # then get the word before it i.e. i-1 index\n",
    "        word1 = sent[i - 1][0]\n",
    "\n",
    "        # then get the pos before it i.e. i-1 index\n",
    "        postag1 = sent[i - 1][1]\n",
    "\n",
    "        features.update(\n",
    "            {\n",
    "                # setting the lower form of word at index i-1\n",
    "                \"-1:word.lower()\": word1.lower(),\n",
    "                # checking if the word at index i-1 is titlecase\n",
    "                \"-1:word.istitle()\": word1.istitle(),\n",
    "                # checking if the word at index i-1 is uppercase\n",
    "                \"-1:word.isupper()\": word1.isupper(),\n",
    "                # setting the pos of word at index i-1\n",
    "                \"-1:postag\": postag1,\n",
    "                # get first 2 letters for the POS tag for i-1 indexed word\n",
    "                \"-1:postag[:2]\": postag1[:2],\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        # setting the BOS or Begining of sentence to True\n",
    "        features[\"BOS\"] = True\n",
    "\n",
    "    # if word is at the end of sentence\n",
    "    if i < len(sent) - 1:\n",
    "\n",
    "        # if word is not the end of sentence\n",
    "        # then get the word after it i.e. i+1 index\n",
    "        word1 = sent[i + 1][0]\n",
    "\n",
    "        # then get the pos after it i.e. i+1 index\n",
    "        postag1 = sent[i + 1][1]\n",
    "\n",
    "        features.update(\n",
    "            {\n",
    "                # setting the lower form of word at index i+1\n",
    "                \"+1:word.lower()\": word1.lower(),\n",
    "                # checking if the word at index i+1 is titlecase\n",
    "                \"+1:word.istitle()\": word1.istitle(),\n",
    "                # checking if the word at index i+1 is titlecase\n",
    "                \"+1:word.isupper()\": word1.isupper(),\n",
    "                # setting the pos of word at index i+1\n",
    "                \"+1:postag\": postag1,\n",
    "                # get first 2 letters for the POS tag for i+1 indexed word\n",
    "                \"+1:postag[:2]\": postag1[:2],\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        # setting the EOS or End of sentence to True\n",
    "        features[\"EOS\"] = True\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "    \"\"\"Convert sentences which are lists containing (w, p, t) into features\"\"\"\n",
    "    return [word2features(sent, i) for i in range(len(sent))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2labels(sent):\n",
    "    \"\"\"Retrieve all the labels from sentences which are lists containing (w, p, t)\"\"\"\n",
    "    return [label for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "boundary = math.ceil(len(X) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "x_train = X[:boundary]\n",
    "y_train = y[:boundary]\n",
    "\n",
    "# test data\n",
    "x_test = X[boundary:]\n",
    "y_test = y[boundary:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating CRF model with Gradient Descent\n",
    "crf = CRF(algorithm=\"lbfgs\", c1=0.1, c2=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the model using train data\n",
    "crf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get all the labels/tags of data\n",
    "labels = list(crf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are not interested in 'O' tags we will check the performance of the CRF model using f1 scores for every tag except O tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.remove(\"O\")\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing predictions based on the fitted model\n",
    "y_pred = crf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the f1 score\n",
    "metrics.flat_f1_score(y_test, y_pred, average=\"weighted\", labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the f1 score\n",
    "print(metrics.flat_classification_report(y_test, y_pred, labels=labels, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model overfits!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_weights(crf, top=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regularization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating a CRF Hyperparameter tuned model\n",
    "crf_reg = CRF(algorithm=\"lbfgs\", c1=5, c2=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fitting the hyperparameters\n",
    "crf_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using the best CRF model\n",
    "y_pred = crf_reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the f1 evaluation metric\n",
    "print(metrics.flat_classification_report(y_test, y_pred, labels=labels, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_weights(crf_reg, top=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Untagged Data Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untagged_test_data = pd.read_csv(\"./Untagged Test Data/untagged_test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untagged_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(untagged_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func_test = lambda s: [\n",
    "    (w, p) for w, p in zip(s[\"word\"].values.tolist(), s[\"pos\"].values.tolist())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_test = untagged_test_data.groupby([\"recipe_name\", \"Step#\"]).apply(agg_func_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [s for s in grouped_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_untagged_test = [sent2features(s) for s in test_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_untagged_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = crf_reg.predict(X_untagged_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for l in pred_test:\n",
    "    for tag in l:\n",
    "        if tag == \"U-Action\":\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(untagged_test_data[\"word\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(set(untagged_test_data[\"word\"].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boostrap output to the untagged data df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = []\n",
    "for sublist in pred_test:\n",
    "    for item in sublist:\n",
    "        flat_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untagged_test_data[\"Predicted Output\"] = flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(untagged_test_data[untagged_test_data[\"Predicted Output\"] == \"U-Action\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "untagged_test_data[untagged_test_data[\"Predicted Output\"] == \"U-Action\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
